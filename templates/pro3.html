<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Portfolio</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>My Portfolio</h1>
    </header>
    <div class="container">
        <section class="projects">
            <div class="project">
                <h2>TOXIC COMMENT DETECTION AND CLASSIFICATION</h2>
                <p>The goal of this Machine Learning project is to use deep learning and Natural Language Processing 
                    (NLP) techniques to create a toxicity detection system. Using a dataset of text comments and their 
                    corresponding toxicity labels, the project trains a machine learning model that can recognize different 
                    types of toxicity, including "toxic," "severe toxic," "obscene," "threat," "insult," and "identity hate." The 
                    project is clearly organized into discrete sections and follows the guidelines for academic writing. The 
                    introduction provides an overview of the assignment's rationale, goal, and parameters. The creation of the 
                    NLP model, including data preprocessing, model architecture, and training protocols, is the primary 
                    emphasis of the project. The Bidirectional LSTM neural network that powers the toxicity detection 
                    model can parse text sequences for classification. The project uses TensorFlow and Keras for model 
                    development. The main conclusions of the project are outlined in the conclusion, which also showcases 
                    the model's effectiveness in the toxin detection assignment. Metrics for training and validation, like 
                    accuracy and loss, are displayed and plotted. The predictions of the model are applied to text input 
                    supplied by users, enabling toxicity evaluation in real-time. Two separate files make up the Python 
                    project: one is used for training the model, and the other is used to evaluate the model with user input. In 
                    order to evaluate text toxicity, the latter file uses a pre-trained tokenizer and a saved model. By showing 
                    how to create a useful and effective toxicity detection model, this effort makes a significant contribution 
                    to the field of NLP. Its ramifications include managing online communities, moderating content, and 
                    identifying offensive language. The Machine Learning project places a strong emphasis on formal 
                    writing requirements for academic writing, such as organization, clarity, and conformity to rules. It is 
                    evidence of the student's aptitude for choosing a research topic, carrying out experiments, and preparing
                    results for academic presentations.</p>
                <img src="/static/assets/img/pro3/1.png" alt="Screenshot of Project 1">
                <img src="/static/assets/img/pro3/2.png" alt="Screenshot of Project 1">
                <img src="/static/assets/img/pro3/3.png" alt="Screenshot of Project 1">
                <img src="/static/assets/img/pro3/4.png" alt="Screenshot of Project 1">
                <img src="/static/assets/img/pro3/5.png" alt="Screenshot of Project 1">
                <img src="/static/assets/img/pro3/6.png" alt="Screenshot of Project 1">
                <img src="/static/assets/img/pro3/7.png" alt="Screenshot of Project 1">
                <img src="/static/assets/img/pro3/8.png" alt="Screenshot of Project 1">
                <img src="/static/assets/img/pro3/9.png" alt="Screenshot of Project 1">

            </div>
            
            <!-- Add more project sections as needed -->
        </section>
    </div>
    <footer>
        <p>&copy; 2024 My Portfolio. All rights reserved.</p>
    </footer>
</body>
</html>
